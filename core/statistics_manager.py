import json
from collections import defaultdict
from datetime import datetime
from typing import Any

from astrbot.api import logger
from astrbot.api.star import StarTools

from ..models.models import (
    DisasterEvent,
    DisasterType,
    EarthquakeData,
    TsunamiData,
    WeatherAlarmData,
)
from ..utils.formatters.weather import COLOR_LEVEL_EMOJI, SORTED_WEATHER_TYPES
from .event_deduplicator import EventDeduplicator


class StatisticsManager:
    """ç¾å®³é¢„è­¦ç»Ÿè®¡ç®¡ç†å™¨"""

    def __init__(self):
        self.data_dir = StarTools.get_data_dir("astrbot_plugin_disaster_warning")
        self.stats_file = self.data_dir / "statistics.json"

        # å†…å­˜ä¸­çš„ç»Ÿè®¡æ•°æ®ç»“æ„
        self.stats: dict[str, Any] = {
            "total_received": 0,  # æ€»æ¥æ”¶æ¬¡æ•°ï¼ˆåŒ…æ‹¬è¢«è¿‡æ»¤çš„ï¼‰
            "total_events": 0,  # ç‹¬ç«‹äº‹ä»¶æ•°ï¼ˆå»é‡åï¼‰
            "start_time": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "by_type": defaultdict(int),
            "by_source": defaultdict(int),
            "earthquake_stats": {
                "by_magnitude": defaultdict(int),  # æŒ‰éœ‡çº§åŒºé—´ç»Ÿè®¡
                "max_magnitude": None,  # è®°å½•æœ€å¤§éœ‡çº§äº‹ä»¶ï¼š{value, event_id, place_name, time}
            },
            "weather_stats": {
                "by_level": defaultdict(int),  # æŒ‰é¢„è­¦çº§åˆ«ç»Ÿè®¡ï¼šç™½ã€è“ã€é»„ã€æ©™ã€çº¢
                "by_type": defaultdict(int),  # æŒ‰é¢„è­¦ç±»å‹ç»Ÿè®¡ï¼šæš´é›¨ã€å¤§é£ç­‰
            },
            "recent_pushes": [],  # æœ€è¿‘æ¨é€è®°å½•è¯¦æƒ…ï¼Œç”¨äºå±•ç¤º
            "recent_event_ids": [],  # æœ€è¿‘å¤„ç†çš„äº‹ä»¶IDåˆ—è¡¨ï¼Œç”¨äºé‡å¯åå»é‡
        }

        # è¿è¡Œæ—¶å»é‡é›†åˆ
        self._recorded_event_ids = set()

        # åˆå§‹åŒ–å»é‡å™¨ç”¨äºç”ŸæˆæŒ‡çº¹ (ä½¿ç”¨é»˜è®¤é…ç½®)
        self.deduplicator = EventDeduplicator()

        # åŠ è½½å†å²æ•°æ®
        self._load_stats()

    def record_push(self, event: DisasterEvent):
        """è®°å½•ä¸€æ¬¡äº‹ä»¶å¤„ç†ï¼ˆæ— è®ºæ˜¯å¦æ¨é€ï¼‰"""
        try:
            current_time = datetime.now().isoformat()
            self.stats["last_updated"] = current_time

            # å…¼å®¹æ—§å­—æ®µåæˆ–åˆå§‹åŒ–æ–°å­—æ®µ
            if "total_received" not in self.stats:
                self.stats["total_received"] = self.stats.get("total_pushes", 0)

            self.stats["total_received"] += 1

            source_id = event.source_id or event.source.value
            self.stats["by_source"][source_id] += 1

            # è®°å½•ç‹¬ç«‹äº‹ä»¶æ•°
            event_unique_id = self._get_unique_event_id(event)
            if event_unique_id not in self._recorded_event_ids:
                self.stats["total_events"] += 1
                self._recorded_event_ids.add(event_unique_id)
                # æ›´æ–°æŒä¹…åŒ–çš„IDåˆ—è¡¨
                self.stats["recent_event_ids"].append(event_unique_id)
                if len(self.stats["recent_event_ids"]) > 500:  # ä¿ç•™æœ€è¿‘500ä¸ªID
                    self.stats["recent_event_ids"] = self.stats["recent_event_ids"][
                        -500:
                    ]

                # 1. åŸºç¡€åˆ†ç±»ç»Ÿè®¡ (ä»…ç»Ÿè®¡ç‹¬ç«‹äº‹ä»¶)
                d_type = event.disaster_type.value
                self.stats["by_type"][d_type] += 1

                # 2. è¯¦ç»†ç»Ÿè®¡ (ä»…ç»Ÿè®¡ç‹¬ç«‹äº‹ä»¶)
                if isinstance(event.data, EarthquakeData):
                    self._record_earthquake_stats(event.data)
                elif isinstance(event.data, WeatherAlarmData):
                    self._record_weather_stats(event.data)

            # 3. æ›´æ–°æœ€è¿‘è®°å½•
            push_record = {
                "timestamp": current_time,
                "event_id": event.id,
                "type": event.disaster_type.value,
                "source": source_id,
                "description": self._get_event_description(event),
            }
            self.stats["recent_pushes"].insert(0, push_record)

            # ä¿æŒæœ€è¿‘è®°å½•æ•°é‡é™åˆ¶
            if len(self.stats["recent_pushes"]) > 100:
                self.stats["recent_pushes"] = self.stats["recent_pushes"][:100]

            # è‡ªåŠ¨ä¿å­˜
            self.save_stats()

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] è®°å½•ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")

    def _get_unique_event_id(self, event: DisasterEvent) -> str:
        """è·å–ç”¨äºå»é‡çš„å”¯ä¸€äº‹ä»¶ID - åŸºäºåœ°ç†ä½ç½®å’Œéœ‡çº§çš„æ¨¡ç³ŠåŒ¹é…"""
        if isinstance(event.data, EarthquakeData):
            # ä½¿ç”¨ EventDeduplicator çš„ç»Ÿä¸€æŒ‡çº¹ç”Ÿæˆé€»è¾‘
            return self.deduplicator.generate_event_fingerprint(event.data)

        return event.id

    def _record_earthquake_stats(self, data: EarthquakeData):
        """è®°å½•åœ°éœ‡è¯¦ç»†ç»Ÿè®¡"""
        # éœ‡çº§åŒºé—´ç»Ÿè®¡ (ç»†åŒ–åˆ†æ®µ)
        mag = data.magnitude
        if mag is not None:
            if mag < 3.0:
                key = "< M3.0"
            elif 3.0 <= mag < 4.0:
                key = "M3.0 - M3.9"
            elif 4.0 <= mag < 5.0:
                key = "M4.0 - M4.9"
            elif 5.0 <= mag < 6.0:
                key = "M5.0 - M5.9"
            elif 6.0 <= mag < 7.0:
                key = "M6.0 - M6.9"
            elif 7.0 <= mag < 8.0:
                key = "M7.0 - M7.9"
            else:
                key = ">= M8.0"
            self.stats["earthquake_stats"]["by_magnitude"][key] += 1

            # æœ€å¤§éœ‡çº§è®°å½• (ä»…è®°å½•æ­£å¼æµ‹å®šæˆ–ç‰¹å®šå¯ä¿¡æº)
            # è¿‡æ»¤æ¡ä»¶ï¼šå¿…é¡»æ˜¯æ­£å¼æµ‹å®š(info_type="æ­£å¼æµ‹å®š") æˆ– å¯ä¿¡åº¦é«˜çš„æ•°æ®æº(å¦‚CENC/USGS/JMAåœ°éœ‡æƒ…æŠ¥)
            is_reliable = False

            # 1. åŸºç¡€ç­›é€‰ï¼šå¿…é¡»æ˜¯åœ°éœ‡æƒ…æŠ¥ç±»å‹ (æ’é™¤EEWé¢„è­¦)
            if data.disaster_type == DisasterType.EARTHQUAKE:
                # 2. è¿›é˜¶ç­›é€‰ï¼šæ’é™¤è‡ªåŠ¨æµ‹å®šï¼Œåªä¿ç•™æ­£å¼/å®¡æ ¸åçš„æ•°æ®
                # å¦‚æœæ²¡æœ‰info_typeï¼Œä¸ºäº†ä¿é™©èµ·è§é»˜è®¤ä¸è®°å½•(é˜²æ­¢æ··å…¥æµ‹è¯•æˆ–æœªçŸ¥æ•°æ®)
                if data.info_type:
                    info_lower = data.info_type.lower()

                    # CENC: å¿…é¡»æ˜ç¡®åŒ…å«"æ­£å¼"
                    if "æ­£å¼" in data.info_type:
                        is_reliable = True

                    # USGS: å¿…é¡»åŒ…å«"reviewed"
                    elif "reviewed" in info_lower:
                        is_reliable = True

                    # JMA: æ’é™¤éœ‡åº¦é€ŸæŠ¥(ScalePrompt)ï¼Œåªä¿ç•™åŒ…å«è¯¦ç»†éœ‡æºä¿¡æ¯çš„æŠ¥å‘Š
                    # ScalePrompt (éœ‡åº¦é€ŸæŠ¥) é€šå¸¸æ²¡æœ‰éœ‡çº§æˆ–ä¸å‡†ï¼Œä¸è®¡å…¥ç»Ÿè®¡
                    elif data.info_type in [
                        "Destination",
                        "ScaleAndDestination",
                        "DetailScale",
                    ]:
                        is_reliable = True

                    # JMA (ä¸­æ–‡æè¿°å…¼å®¹): "éœ‡æº"é€šå¸¸å¯¹åº”éœ‡æºæƒ…æŠ¥ï¼Œ"å„åœ°"å¯¹åº”å„åœ°éœ‡åº¦æƒ…æŠ¥
                    # æ’é™¤å•çº¯çš„"éœ‡åº¦é€ŸæŠ¥"
                    elif "éœ‡æº" in data.info_type or "å„åœ°" in data.info_type:
                        is_reliable = True

            if is_reliable:
                current_max = self.stats["earthquake_stats"].get("max_magnitude")
                if current_max is None or mag > current_max.get("value", 0):
                    self.stats["earthquake_stats"]["max_magnitude"] = {
                        "value": mag,
                        "event_id": data.id,
                        "place_name": data.place_name,
                        "time": (
                            data.shock_time.isoformat()
                            if data.shock_time
                            else datetime.now().isoformat()
                        ),
                        "source": data.source.value,  # è®°å½•æ¥æºä»¥ä¾¿è°ƒè¯•
                    }

    def _record_weather_stats(self, data: WeatherAlarmData):
        """è®°å½•æ°”è±¡é¢„è­¦è¯¦ç»†ç»Ÿè®¡"""
        headline = data.headline or ""

        # 1. é¢„è­¦çº§åˆ«ç»Ÿè®¡
        level = "æœªçŸ¥"
        for color, emoji in COLOR_LEVEL_EMOJI.items():
            if color in headline:
                # å­˜å‚¨å¸¦ Emoji çš„é”®åï¼Œæ–¹ä¾¿å±•ç¤º
                level = f"{emoji}{color}"
                break
        self.stats["weather_stats"]["by_level"][level] += 1

        # 2. é¢„è­¦ç±»å‹ç»Ÿè®¡
        w_type = "å…¶ä»–"
        for name in SORTED_WEATHER_TYPES:
            if name in headline:
                w_type = name
                break
        self.stats["weather_stats"]["by_type"][w_type] += 1

    def _get_event_description(self, event: DisasterEvent) -> str:
        """ç”Ÿæˆç®€çŸ­çš„äº‹ä»¶æè¿°"""
        if isinstance(event.data, EarthquakeData):
            return f"M{event.data.magnitude} {event.data.place_name}"
        elif isinstance(event.data, TsunamiData):
            return f"{event.data.title} ({event.data.level})"
        elif isinstance(event.data, WeatherAlarmData):
            return f"{event.data.headline}"
        return "æœªçŸ¥äº‹ä»¶"

    def save_stats(self):
        """ä¿å­˜ç»Ÿè®¡æ•°æ®"""
        try:
            self.data_dir.mkdir(parents=True, exist_ok=True)

            # å°† defaultdict è½¬æ¢ä¸º dict ç”¨äº JSON åºåˆ—åŒ–
            serializable_stats = self._prepare_for_serialization(self.stats)

            with open(self.stats_file, "w", encoding="utf-8") as f:
                json.dump(serializable_stats, f, ensure_ascii=False, indent=2)

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] ä¿å­˜ç»Ÿè®¡æ–‡ä»¶å¤±è´¥: {e}")

    def _prepare_for_serialization(self, data: Any) -> Any:
        """é€’å½’å°† defaultdict è½¬æ¢ä¸º dict"""
        if isinstance(data, defaultdict):
            return {k: self._prepare_for_serialization(v) for k, v in data.items()}
        elif isinstance(data, dict):
            return {k: self._prepare_for_serialization(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._prepare_for_serialization(i) for i in data]
        else:
            return data

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡æ•°æ®"""
        try:
            self.stats = {
                "total_received": 0,
                "total_events": 0,
                "start_time": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat(),
                "by_type": defaultdict(int),
                "by_source": defaultdict(int),
                "earthquake_stats": {
                    "by_magnitude": defaultdict(int),
                    "max_magnitude": None,
                },
                "weather_stats": {
                    "by_level": defaultdict(int),
                    "by_type": defaultdict(int),
                },
                "recent_pushes": [],
                "recent_event_ids": [],
            }
            # æ¸…ç©ºå†…å­˜ä¸­çš„å»é‡é›†åˆ
            self._recorded_event_ids.clear()

            # ä¿å­˜åˆ°æ–‡ä»¶
            self.save_stats()
            logger.info("[ç¾å®³é¢„è­¦] ç»Ÿè®¡æ•°æ®å·²é‡ç½®")

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] é‡ç½®ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")

    def _load_stats(self):
        """åŠ è½½ç»Ÿè®¡æ•°æ®"""
        if not self.stats_file.exists():
            return

        try:
            with open(self.stats_file, encoding="utf-8") as f:
                saved_stats = json.load(f)

            # æ¢å¤æ•°æ®ï¼Œä¿ç•™é»˜è®¤å€¼ç»“æ„
            self._merge_stats(self.stats, saved_stats)

            # æ¢å¤å»é‡é›†åˆ
            if "recent_event_ids" in self.stats:
                self._recorded_event_ids.update(self.stats["recent_event_ids"])

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] åŠ è½½ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")

    def _merge_stats(self, current: dict, saved: dict):
        """é€’å½’åˆå¹¶ç»Ÿè®¡æ•°æ®"""
        for k, v in saved.items():
            if k in current:
                if isinstance(current[k], defaultdict) and isinstance(v, dict):
                    # æ¢å¤ defaultdict
                    for sub_k, sub_v in v.items():
                        current[k][sub_k] = sub_v
                elif isinstance(current[k], dict) and isinstance(v, dict):
                    self._merge_stats(current[k], v)
                else:
                    current[k] = v
            else:
                current[k] = v

    def get_summary(self) -> str:
        """è·å–ç»Ÿè®¡æ‘˜è¦æ–‡æœ¬"""
        s = self.stats

        # åŸºç¡€ä¿¡æ¯
        total = s.get("total_received", s.get("total_pushes", 0))
        text = [
            "ğŸ“Š ç¾å®³é¢„è­¦ç»Ÿè®¡æŠ¥å‘Š",
            f"ğŸ“… ç»Ÿè®¡å¼€å§‹æ—¶é—´: {s['start_time'][:19].replace('T', ' ')}",
            f"ğŸ”¢ è®°å½•åˆ°çš„äº‹ä»¶æ€»æ•°: {total}",
            f"ğŸš¨ å»é‡åçš„äº‹ä»¶æ€»æ•°: {s['total_events']}",
            "",
            "ğŸ“ˆ åˆ†ç±»ç»Ÿè®¡:",
        ]

        # ç±»å‹ç»Ÿè®¡
        type_map = {
            "earthquake": "åœ°éœ‡",
            "earthquake_warning": "åœ°éœ‡é¢„è­¦",
            "tsunami": "æµ·å•¸",
            "weather_alarm": "æ°”è±¡",
        }
        for type_key, count in s["by_type"].items():
            type_name = type_map.get(type_key, type_key)
            text.append(f"{type_name}: {count}")

        # åœ°éœ‡è¯¦æƒ…
        text.extend(["", "ğŸŒ åœ°éœ‡éœ‡çº§åˆ†å¸ƒ:"])
        eq_stats = s["earthquake_stats"]["by_magnitude"]
        # æ’åºå±•ç¤º
        order = [
            "< M3.0",
            "M3.0 - M3.9",
            "M4.0 - M4.9",
            "M5.0 - M5.9",
            "M6.0 - M6.9",
            "M7.0 - M7.9",
            ">= M8.0",
        ]
        has_eq = False
        for key in order:
            count = eq_stats.get(key, 0)
            if count > 0:
                text.append(f"{key}: {count}")
                has_eq = True
        if not has_eq:
            text.append("(æš‚æ— æ•°æ®)")

        max_mag = s["earthquake_stats"].get("max_magnitude")
        if max_mag:
            source_val = max_mag.get("source")
            # åªæœ‰å½“source_valå­˜åœ¨æ—¶æ‰æ˜¾ç¤ºæ‹¬å·å†…å®¹
            source_info = f" ({source_val})" if source_val else ""
            text.extend(
                [
                    "",
                    f"ğŸ”¥ æœ€å¤§åœ°éœ‡: M{max_mag['value']} {max_mag['place_name']}{source_info}",
                    "",
                ]
            )

        # æ°”è±¡è¯¦æƒ…
        text.append("â˜ï¸ æ°”è±¡é¢„è­¦åˆ†å¸ƒ:")
        text.append("")
        weather_level = s["weather_stats"]["by_level"]
        level_order = ["ğŸ”´çº¢è‰²", "ğŸŸ æ©™è‰²", "ğŸŸ¡é»„è‰²", "ğŸ”µè“è‰²", "âšªç™½è‰²", "æœªçŸ¥"]
        has_weather = False

        # ç»Ÿè®¡ç±»å‹åˆ†å¸ƒ
        weather_type = s["weather_stats"]["by_type"]
        sorted_types = sorted(weather_type.items(), key=lambda x: x[1], reverse=True)
        if sorted_types:
            text.append("ç±»å‹Top10:")
            for t, c in sorted_types[:10]:
                text.append(f"{t}: {c}")

        # ç»Ÿè®¡çº§åˆ«åˆ†å¸ƒ
        text.append("\nçº§åˆ«åˆ†å¸ƒ:")
        for level in level_order:
            count = weather_level.get(level, 0)
            if count > 0:
                text.append(f"{level}: {count}")
                has_weather = True

        if not has_weather and not sorted_types:
            text.append("(æš‚æ— æ•°æ®)")

        # æ•°æ®æºç»Ÿè®¡
        text.extend(["", "ğŸ“¡ æ•°æ®æºäº‹ä»¶ç»Ÿè®¡:"])
        # æŒ‰æ•°é‡é™åºæ’åˆ—
        sorted_sources = sorted(
            s["by_source"].items(), key=lambda x: x[1], reverse=True
        )
        for source, count in sorted_sources[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
            text.append(f"{source}: {count}")

        return "\n".join(text)
