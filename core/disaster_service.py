"""
ç¾å®³é¢„è­¦æ ¸å¿ƒæœåŠ¡
æ•´åˆæ‰€æœ‰é‡æ„çš„ç»„ä»¶
"""

import asyncio
import json
import traceback
from datetime import datetime
from typing import Any

from astrbot.api import logger

from ..models.models import (
    DataSource,
    DisasterEvent,
    DisasterType,
    EarthquakeData,
    TsunamiData,
    WeatherAlarmData,
)
from .handler_registry import WebSocketHandlerRegistry
from .handlers import DATA_HANDLERS
from .message_logger import MessageLogger
from .message_manager import MessagePushManager
from .statistics_manager import StatisticsManager
from .websocket_manager import HTTPDataFetcher, WebSocketManager


class DisasterWarningService:
    """ç¾å®³é¢„è­¦æ ¸å¿ƒæœåŠ¡"""

    def __init__(self, config: dict[str, Any], context):
        self.config = config
        self.context = context
        self.running = False

        # åˆå§‹åŒ–æ¶ˆæ¯è®°å½•å™¨
        self.message_logger = MessageLogger(config, "disaster_warning")

        # åˆå§‹åŒ–ç»Ÿè®¡ç®¡ç†å™¨
        self.statistics_manager = StatisticsManager()

        # åˆå§‹åŒ–ç»„ä»¶
        self.ws_manager = WebSocketManager(
            config.get("websocket_config", {}), self.message_logger
        )
        self.http_fetcher: HTTPDataFetcher | None = None
        self.message_manager = MessagePushManager(config, context)

        # æ•°æ®å¤„ç†å™¨
        self.handlers = {}
        self._initialize_handlers()

        # è¿æ¥é…ç½®
        self.connections = {}
        self.connection_tasks = []

        # å®šæ—¶ä»»åŠ¡
        self.scheduled_tasks = []

    def _initialize_handlers(self):
        """åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨"""
        for source_id, handler_class in DATA_HANDLERS.items():
            self.handlers[source_id] = handler_class(self.message_logger)

    async def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        try:
            logger.info("[ç¾å®³é¢„è­¦] æ­£åœ¨åˆå§‹åŒ–ç¾å®³é¢„è­¦æœåŠ¡...")

            # åˆå§‹åŒ–HTTPè·å–å™¨
            self.http_fetcher = HTTPDataFetcher(self.config)

            # æ³¨å†ŒWebSocketæ¶ˆæ¯å¤„ç†å™¨
            self._register_handlers()

            # é…ç½®è¿æ¥
            self._configure_connections()

            logger.info("[ç¾å®³é¢„è­¦] ç¾å®³é¢„è­¦æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] åˆå§‹åŒ–æœåŠ¡å¤±è´¥: {e}")
            raise

    def _register_handlers(self):
        """æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨"""
        registry = WebSocketHandlerRegistry(self)
        registry.register_all(self.ws_manager)

    def _configure_connections(self):
        """é…ç½®è¿æ¥ - é€‚é…æ•°æ®æºé…ç½®"""
        data_sources = self.config.get("data_sources", {})

        # FAN Studioè¿æ¥é…ç½®
        fan_studio_config = data_sources.get("fan_studio", {})
        if isinstance(fan_studio_config, dict) and fan_studio_config.get(
            "enabled", True
        ):
            # FAN Studio æœåŠ¡å™¨åœ°å€
            # æ­£å¼æœåŠ¡å™¨: wss://ws.fanstudio.tech/[è·¯å¾„]
            # å¤‡ç”¨æœåŠ¡å™¨: wss://ws.fanstudio.hk/[è·¯å¾„]
            primary_server = "wss://ws.fanstudio.tech"
            backup_server = "wss://ws.fanstudio.hk"

            # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è‡³å°‘ä¸€ä¸ª FAN Studio å­æ•°æ®æº
            fan_sub_sources = [
                "china_earthquake_warning",
                "taiwan_cwa_earthquake",
                "china_cenc_earthquake",
                "usgs_earthquake",
                "china_weather_alarm",
                "china_tsunami",
                "japan_jma_eew",
            ]

            any_fan_source_enabled = any(
                fan_studio_config.get(source, True) for source in fan_sub_sources
            )

            if any_fan_source_enabled:
                # ä½¿ç”¨ /all è·¯å¾„å»ºç«‹å•ä¸€è¿æ¥
                self.connections["fan_studio_all"] = {
                    "url": f"{primary_server}/all",
                    "backup_url": f"{backup_server}/all",
                    "handler": "fan_studio",
                }
                logger.info("[ç¾å®³é¢„è­¦] å·²é…ç½® FAN Studio å…¨é‡æ•°æ®è¿æ¥ (/all)")

        # P2Pè¿æ¥é…ç½®
        p2p_config = data_sources.get("p2p_earthquake", {})
        if isinstance(p2p_config, dict) and p2p_config.get("enabled", True):
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•P2Pæ•°æ®æºè¢«å¯ç”¨
            p2p_enabled = False
            if p2p_config.get("japan_jma_eew", True):
                p2p_enabled = True
            if p2p_config.get("japan_jma_earthquake", True):
                p2p_enabled = True
            if p2p_config.get("japan_jma_tsunami", True):
                p2p_enabled = True

            if p2p_enabled:
                self.connections["p2p_main"] = {
                    "url": "wss://api.p2pquake.net/v2/ws",
                    "handler": "p2p",
                }

        # Wolfxè¿æ¥é…ç½®
        wolfx_config = data_sources.get("wolfx", {})
        if isinstance(wolfx_config, dict) and wolfx_config.get("enabled", True):
            wolfx_sources = [
                ("japan_jma_eew", "wss://ws-api.wolfx.jp/jma_eew"),
                ("china_cenc_eew", "wss://ws-api.wolfx.jp/cenc_eew"),
                ("taiwan_cwa_eew", "wss://ws-api.wolfx.jp/cwa_eew"),
                ("japan_jma_earthquake", "wss://ws-api.wolfx.jp/jma_eqlist"),
                ("china_cenc_earthquake", "wss://ws-api.wolfx.jp/cenc_eqlist"),
            ]

            for source_key, url in wolfx_sources:
                if wolfx_config.get(source_key, True):
                    conn_name = f"wolfx_{source_key}"
                    self.connections[conn_name] = {"url": url, "handler": "wolfx"}

        # Global Quakeè¿æ¥é…ç½® - æœåŠ¡å™¨åœ°å€ç¡¬ç¼–ç ï¼Œç”¨æˆ·åªéœ€é…ç½®æ˜¯å¦å¯ç”¨
        global_quake_config = data_sources.get("global_quake", {})
        if isinstance(global_quake_config, dict) and global_quake_config.get(
            "enabled", False
        ):
            # GlobalQuake Monitor æœåŠ¡å™¨åœ°å€ï¼ˆç¡¬ç¼–ç ï¼‰
            global_quake_url = "wss://gqm.aloys233.top/ws"
            self.connections["global_quake"] = {
                "url": global_quake_url,
                "handler": "global_quake",
            }
            logger.info("[ç¾å®³é¢„è­¦] Global Quake æ•°æ®æºå·²å¯ç”¨")

    async def start(self):
        """å¯åŠ¨æœåŠ¡"""
        if self.running:
            return

        try:
            self.running = True
            self.start_time = datetime.now()  # è®°å½•å¯åŠ¨æ—¶é—´
            logger.info("[ç¾å®³é¢„è­¦] æ­£åœ¨å¯åŠ¨ç¾å®³é¢„è­¦æœåŠ¡...")

            # å¯åŠ¨WebSocketç®¡ç†å™¨
            await self.ws_manager.start()

            # å»ºç«‹WebSocketè¿æ¥
            await self._establish_websocket_connections()

            # å¯åŠ¨Global Quakeè¿æ¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            await self._start_global_quake_connection()

            # å¯åŠ¨å®šæ—¶HTTPæ•°æ®è·å–
            await self._start_scheduled_http_fetch()

            # å¯åŠ¨æ¸…ç†ä»»åŠ¡
            await self._start_cleanup_task()

            # æ£€æŸ¥å¹¶æç¤ºæ—¥å¿—è®°å½•å™¨çŠ¶æ€
            if self.message_logger.enabled:
                logger.info(
                    f"[ç¾å®³é¢„è­¦] åŸå§‹æ¶ˆæ¯æ—¥å¿—è®°å½•å·²å¯ç”¨ï¼Œæ—¥å¿—æ–‡ä»¶: {self.message_logger.log_file_path}"
                )
            else:
                logger.info(
                    "[ç¾å®³é¢„è­¦] åŸå§‹æ¶ˆæ¯æ—¥å¿—è®°å½•æœªå¯ç”¨ã€‚å¦‚éœ€è°ƒè¯•æˆ–è®°å½•åŸå§‹æ•°æ®ï¼Œè¯·ä½¿ç”¨å‘½ä»¤ '/ç¾å®³é¢„è­¦æ—¥å¿—å¼€å…³' å¯ç”¨ã€‚"
                )

            logger.info("[ç¾å®³é¢„è­¦] ç¾å®³é¢„è­¦æœåŠ¡å·²å¯åŠ¨")

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] å¯åŠ¨æœåŠ¡å¤±è´¥: {e}")
            self.running = False
            raise

    async def stop(self):
        """åœæ­¢æœåŠ¡"""
        if not self.running:
            return

        try:
            self.running = False
            logger.info("[ç¾å®³é¢„è­¦] æ­£åœ¨åœæ­¢ç¾å®³é¢„è­¦æœåŠ¡...")

            # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
            for task in self.connection_tasks:
                task.cancel()

            for task in self.scheduled_tasks:
                task.cancel()

            # åœæ­¢WebSocketç®¡ç†å™¨
            await self.ws_manager.stop()

            # å…³é—­HTTPè·å–å™¨
            if self.http_fetcher:
                await self.http_fetcher.__aexit__(None, None, None)

            logger.info("[ç¾å®³é¢„è­¦] ç¾å®³é¢„è­¦æœåŠ¡å·²åœæ­¢")

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] åœæ­¢æœåŠ¡æ—¶å‡ºé”™: {e}")

    async def _establish_websocket_connections(self):
        """å»ºç«‹WebSocketè¿æ¥ - ä½¿ç”¨WebSocketç®¡ç†å™¨åŠŸèƒ½"""
        for conn_name, conn_config in self.connections.items():
            if conn_config["handler"] in ["fan_studio", "p2p", "wolfx", "global_quake"]:
                # ä½¿ç”¨WebSocketç®¡ç†å™¨åŠŸèƒ½ï¼Œä¼ é€’è¿æ¥ä¿¡æ¯
                connection_info = {
                    "connection_name": conn_name,
                    "handler_type": conn_config["handler"],
                    "data_source": self._get_data_source_from_connection(conn_name),
                    "established_time": None,
                    "backup_url": conn_config.get("backup_url"),  # ä¼ é€’å¤‡ç”¨æœåŠ¡å™¨URL
                }

                task = asyncio.create_task(
                    self.ws_manager.connect(
                        name=conn_name,
                        uri=conn_config["url"],
                        connection_info=connection_info,
                    )
                )
                self.connection_tasks.append(task)

                # æ—¥å¿—ä¸­æ˜¾ç¤ºå¤‡ç”¨æœåŠ¡å™¨ä¿¡æ¯
                backup_info = (
                    f", å¤‡ç”¨: {conn_config.get('backup_url')}"
                    if conn_config.get("backup_url")
                    else ""
                )
                logger.info(
                    f"[ç¾å®³é¢„è­¦] å·²å¯åŠ¨WebSocketè¿æ¥ä»»åŠ¡: {conn_name} (æ•°æ®æº: {connection_info['data_source']}{backup_info})"
                )

    def _get_data_source_from_connection(self, connection_name: str) -> str:
        """ä»è¿æ¥åç§°è·å–æ•°æ®æºID"""
        # è¿æ¥åç§°åˆ°æ•°æ®æºIDçš„æ˜ å°„
        connection_mapping = {
            # FAN Studio
            "fan_studio_all": "fan_studio_mixed",  # æ··åˆæ•°æ®æº
            # P2P
            "p2p_main": "jma_p2p",
            # Wolfx
            "wolfx_japan_jma_eew": "jma_wolfx",
            "wolfx_china_cenc_eew": "cea_wolfx",
            "wolfx_taiwan_cwa_eew": "cwa_wolfx",
            "wolfx_china_cenc_earthquake": "cenc_wolfx",
            "wolfx_japan_jma_earthquake": "jma_wolfx_info",
            # Global Quake
            "global_quake": "global_quake",
        }

        return connection_mapping.get(connection_name, "unknown")

    def is_fan_studio_source_enabled(self, source_key: str) -> bool:
        """æ£€æŸ¥ç‰¹å®šçš„ FAN Studio æ•°æ®æºæ˜¯å¦å¯ç”¨"""
        data_sources = self.config.get("data_sources", {})
        fan_studio_config = data_sources.get("fan_studio", {})

        if not isinstance(fan_studio_config, dict) or not fan_studio_config.get(
            "enabled", True
        ):
            return False

        return fan_studio_config.get(source_key, True)

    async def _start_global_quake_connection(self):
        """å¯åŠ¨Global Quake WebSocketè¿æ¥ - ç°å·²æ•´åˆåˆ° WebSocketManagerï¼Œæ­¤æ–¹æ³•ä¿ç•™ä»…ç”¨äºæ—¥å¿—"""
        # Global Quake ç°åœ¨é€šè¿‡ _configure_connections å’Œ _establish_websocket_connections ç»Ÿä¸€ç®¡ç†
        # æ­¤æ–¹æ³•ä¿ç•™ä»¥ä¿æŒå‘åå…¼å®¹ï¼Œä½†ä¸å†æ‰§è¡Œä»»ä½•æ“ä½œ
        global_quake_config = self.config.get("data_sources", {}).get(
            "global_quake", {}
        )
        if isinstance(global_quake_config, dict) and global_quake_config.get(
            "enabled", False
        ):
            if "global_quake" in self.connections:
                logger.debug("[ç¾å®³é¢„è­¦] Global Quake å·²é€šè¿‡ WebSocketManager ç»Ÿä¸€ç®¡ç†")

    async def _start_scheduled_http_fetch(self):
        """å¯åŠ¨å®šæ—¶HTTPæ•°æ®è·å–"""

        async def fetch_wolfx_data():
            while self.running:
                try:
                    await asyncio.sleep(300)  # 5åˆ†é’Ÿè·å–ä¸€æ¬¡

                    async with self.http_fetcher as fetcher:
                        # è·å–ä¸­å›½åœ°éœ‡å°ç½‘åœ°éœ‡åˆ—è¡¨
                        cenc_data = await fetcher.fetch_json(
                            "https://api.wolfx.jp/cenc_eqlist.json"
                        )
                        if cenc_data:
                            # è®°å½•åŸå§‹HTTPå“åº”æ•°æ®ï¼ˆä»…æ‘˜è¦ï¼Œé¿å…æ—¥å¿—è†¨èƒ€ï¼‰
                            if self.message_logger:
                                try:
                                    self.message_logger.log_http_earthquake_list(
                                        source="http_wolfx_cenc",
                                        url="https://api.wolfx.jp/cenc_eqlist.json",
                                        earthquake_list=cenc_data,
                                        max_items=5,
                                    )
                                except Exception as log_e:
                                    logger.warning(
                                        f"[ç¾å®³é¢„è­¦] HTTPå“åº”è®°å½•å¤±è´¥: {log_e}"
                                    )

                            # ä½¿ç”¨æ–°å¤„ç†å™¨
                            handler = self.handlers.get("cenc_wolfx")
                            if handler:
                                event = handler.parse_message(json.dumps(cenc_data))
                                if event:
                                    await self._handle_disaster_event(event)

                        # è·å–æ—¥æœ¬æ°”è±¡å…åœ°éœ‡åˆ—è¡¨
                        jma_data = await fetcher.fetch_json(
                            "https://api.wolfx.jp/jma_eqlist.json"
                        )
                        if jma_data:
                            # è®°å½•åŸå§‹HTTPå“åº”æ•°æ®ï¼ˆä»…æ‘˜è¦ï¼Œé¿å…æ—¥å¿—è†¨èƒ€ï¼‰
                            if self.message_logger:
                                try:
                                    self.message_logger.log_http_earthquake_list(
                                        source="http_wolfx_jma",
                                        url="https://api.wolfx.jp/jma_eqlist.json",
                                        earthquake_list=jma_data,
                                        max_items=5,
                                    )
                                except Exception as log_e:
                                    logger.warning(
                                        f"[ç¾å®³é¢„è­¦] HTTPå“åº”è®°å½•å¤±è´¥: {log_e}"
                                    )

                            # ä½¿ç”¨æ–°å¤„ç†å™¨
                            handler = self.handlers.get("jma_wolfx_info")
                            if handler:
                                event = handler.parse_message(json.dumps(jma_data))
                                if event:
                                    await self._handle_disaster_event(event)

                except Exception as e:
                    logger.error(f"[ç¾å®³é¢„è­¦] å®šæ—¶HTTPæ•°æ®è·å–å¤±è´¥: {e}")

        task = asyncio.create_task(fetch_wolfx_data())
        self.scheduled_tasks.append(task)

    async def _start_cleanup_task(self):
        """å¯åŠ¨æ¸…ç†ä»»åŠ¡"""

        async def cleanup():
            while self.running:
                try:
                    await asyncio.sleep(86400)  # æ¯å¤©æ¸…ç†ä¸€æ¬¡
                    self.message_manager.cleanup_old_records()
                except Exception as e:
                    logger.error(f"[ç¾å®³é¢„è­¦] æ¸…ç†ä»»åŠ¡å¤±è´¥: {e}")

        task = asyncio.create_task(cleanup())
        self.scheduled_tasks.append(task)

    def is_in_silence_period(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¤„äºå¯åŠ¨åçš„é™é»˜æœŸ"""
        if not hasattr(self, "start_time"):
            return False

        debug_config = self.config.get("debug_config", {})
        silence_duration = debug_config.get("startup_silence_duration", 0)

        if silence_duration <= 0:
            return False

        elapsed = (datetime.now() - self.start_time).total_seconds()
        return elapsed < silence_duration

    async def _handle_disaster_event(self, event: DisasterEvent):
        """å¤„ç†ç¾å®³äº‹ä»¶"""
        # æ£€æŸ¥é™é»˜æœŸ
        if self.is_in_silence_period():
            debug_config = self.config.get("debug_config", {})
            silence_duration = debug_config.get("startup_silence_duration", 0)
            elapsed = (datetime.now() - self.start_time).total_seconds()
            logger.debug(
                f"[ç¾å®³é¢„è­¦] å¤„äºå¯åŠ¨é™é»˜æœŸ (å‰©ä½™ {silence_duration - elapsed:.1f}s)ï¼Œå¿½ç•¥äº‹ä»¶: {event.id}"
            )
            # é™é»˜æœŸå†…ä¸è®°å½•ç»Ÿè®¡æ•°æ®ï¼Œç›´æ¥è¿”å›
            return

        try:
            logger.debug(f"[ç¾å®³é¢„è­¦] å¤„ç†ç¾å®³äº‹ä»¶: {event.id}")
            self._log_event(event)

            # è®°å½•ç»Ÿè®¡æ•°æ® (ä¸ç®¡æ˜¯å¦æ¨é€æˆåŠŸ)
            self.statistics_manager.record_push(event)

            # æ¨é€æ¶ˆæ¯ - ä½¿ç”¨æ–°æ¶ˆæ¯ç®¡ç†å™¨
            push_result = await self.message_manager.push_event(event)
            if push_result:
                logger.debug(f"[ç¾å®³é¢„è­¦] âœ… äº‹ä»¶æ¨é€æˆåŠŸ: {event.id}")
            else:
                logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶æ¨é€è¢«è¿‡æ»¤: {event.id}")

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] å¤„ç†ç¾å®³äº‹ä»¶å¤±è´¥: {e}")
            logger.error(
                f"[ç¾å®³é¢„è­¦] å¤±è´¥çš„äº‹ä»¶ID: {event.id if hasattr(event, 'id') else 'unknown'}"
            )
            logger.error(f"[ç¾å®³é¢„è­¦] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")

    def _log_event(self, event: DisasterEvent):
        """è®°å½•äº‹ä»¶æ—¥å¿—"""
        try:
            if isinstance(event.data, EarthquakeData):
                earthquake = event.data
                log_info = f"åœ°éœ‡äº‹ä»¶ - éœ‡çº§: M{earthquake.magnitude}, ä½ç½®: {earthquake.place_name}, æ—¶é—´: {earthquake.shock_time}, æ•°æ®æº: {event.source.value}"
            elif isinstance(event.data, TsunamiData):
                tsunami = event.data
                log_info = f"æµ·å•¸äº‹ä»¶ - çº§åˆ«: {tsunami.level}, æ ‡é¢˜: {tsunami.title}, æ•°æ®æº: {event.source.value}"
            elif isinstance(event.data, WeatherAlarmData):
                weather = event.data
                log_info = (
                    f"æ°”è±¡äº‹ä»¶ - æ ‡é¢˜: {weather.headline}, æ•°æ®æº: {event.source.value}"
                )
            else:
                log_info = (
                    f"æœªçŸ¥äº‹ä»¶ç±»å‹ - ID: {event.id}, æ•°æ®æº: {event.source.value}"
                )

            logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶è¯¦æƒ…: {log_info}")
        except Exception:
            logger.debug(
                f"[ç¾å®³é¢„è­¦] äº‹ä»¶è¯¦æƒ…: ID={event.id}, ç±»å‹={event.disaster_type.value}, æ•°æ®æº={event.source.value}"
            )

    def get_service_status(self) -> dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€ - å¢å¼ºç‰ˆæœ¬"""
        # è·å–WebSocketè¿æ¥çŠ¶æ€
        connection_status = self.ws_manager.get_all_connections_status()

        # ç»Ÿè®¡æ´»è·ƒè¿æ¥
        active_websocket_connections = sum(
            1 for status in connection_status.values() if status["connected"]
        )

        # ç»Ÿè®¡Global Quakeè¿æ¥ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        global_quake_connected = any(
            "global_quake" in task.get_name() if hasattr(task, "get_name") else False
            for task in self.connection_tasks
        )

        return {
            "running": self.running,
            "active_websocket_connections": active_websocket_connections,
            "global_quake_connected": global_quake_connected,
            "total_connections": len(connection_status),
            "connection_details": connection_status,
            "statistics_summary": self.statistics_manager.get_summary(),
            "data_sources": self._get_active_data_sources(),
            "message_logger_enabled": self.message_logger.enabled
            if self.message_logger
            else False,
            "uptime": self._get_uptime(),  # æ·»åŠ è¿è¡Œæ—¶é—´
        }

    def _get_uptime(self) -> str:
        """è·å–æœåŠ¡è¿è¡Œæ—¶é—´"""
        if not self.running or not hasattr(self, "start_time"):
            return "æœªè¿è¡Œ"

        delta = datetime.now() - self.start_time
        days = delta.days
        hours, remainder = divmod(delta.seconds, 3600)
        minutes, seconds = divmod(remainder, 60)

        parts = []
        if days > 0:
            parts.append(f"{days}å¤©")
        if hours > 0:
            parts.append(f"{hours}å°æ—¶")
        if minutes > 0:
            parts.append(f"{minutes}åˆ†")
        parts.append(f"{seconds}ç§’")

        return "".join(parts)

    def _get_active_data_sources(self) -> list[str]:
        """è·å–æ´»è·ƒçš„æ•°æ®æº"""
        active_sources = []
        data_sources = self.config.get("data_sources", {})

        # éå†é…ç½®ç»“æ„ï¼Œæ”¶é›†å¯ç”¨çš„æ•°æ®æº
        for service_name, service_config in data_sources.items():
            if isinstance(service_config, dict) and service_config.get(
                "enabled", False
            ):
                # æ”¶é›†è¯¥æœåŠ¡ä¸‹å¯ç”¨çš„å…·ä½“æ•°æ®æº
                for source_name, enabled in service_config.items():
                    if (
                        source_name != "enabled"
                        and isinstance(enabled, bool)
                        and enabled
                    ):
                        active_sources.append(f"{service_name}.{source_name}")

        return active_sources

    async def test_push(
        self, session: str, disaster_type: str = "earthquake", test_type: str = None
    ):
        """æµ‹è¯•æ¨é€åŠŸèƒ½ - é¢„è®¾ç¬¦åˆå®é™…æ¶ˆæ¯æ ¼å¼åŒ–å™¨çš„æ•°æ®æ ¼å¼"""
        try:
            # é¢„è®¾æµ‹è¯•é…ç½®ï¼Œå¯¹åº”ä¸åŒçš„æ¶ˆæ¯æ ¼å¼åŒ–å™¨
            test_configs = {
                "earthquake": {
                    "china_eew": {  # ä¸­å›½åœ°éœ‡é¢„è­¦ç½‘æ ¼å¼
                        "source_id": "cea_fanstudio",
                        "magnitude": 5.5,
                        "depth": 10.0,
                        "intensity": 6.0,
                        "place_name": "æµ‹è¯•åœ°å",
                        "latitude": 31.2,
                        "longitude": 103.8,
                        "updates": 1,
                        "is_final": False,
                    },
                    "japan_eew": {  # æ—¥æœ¬ç´§æ€¥åœ°éœ‡é€ŸæŠ¥æ ¼å¼
                        "source_id": "jma_wolfx",
                        "magnitude": 6.2,
                        "depth": 35.0,
                        "scale": 5.0,  # éœ‡åº¦
                        "place_name": "æµ‹è¯•åœ°å",
                        "latitude": 37.5,
                        "longitude": 141.8,
                        "updates": 2,
                        "is_final": False,
                        "raw_data": {
                            "areas": [
                                {
                                    "name": "æµ‹è¯•åŒºåŸŸ1",
                                    "scaleFrom": 50,
                                    "kindCode": "10",
                                },  # éœ‡åº¦5å¼ºï¼Œæœªåˆ°è¾¾
                                {
                                    "name": "æµ‹è¯•åŒºåŸŸ2",
                                    "scaleFrom": 45,
                                    "kindCode": "11",
                                },  # éœ‡åº¦5å¼±ï¼Œå·²åˆ°è¾¾
                            ]
                        },
                    },
                    "usgs_info": {  # USGSåœ°éœ‡æƒ…æŠ¥æ ¼å¼
                        "source_id": "usgs_fanstudio",
                        "magnitude": 4.8,
                        "depth": 15.5,
                        "place_name": "æµ‹è¯•åœ°å",
                        "latitude": 34.1,
                        "longitude": -118.2,
                        "info_type": "automatic",
                    },
                },
                "tsunami": {
                    "china_tsunami": {  # ä¸­å›½æµ·å•¸é¢„è­¦æ ¼å¼
                        "source_id": "china_tsunami_fanstudio",
                        "title": "æµ·å•¸é»„è‰²è­¦æŠ¥",
                        "level": "Warning",
                        "org_unit": "è‡ªç„¶èµ„æºéƒ¨æµ·å•¸é¢„è­¦ä¸­å¿ƒ",
                        "forecasts": [
                            {
                                "name": "æµ‹è¯•æµ·åŸŸ",
                                "grade": "Warning",
                                "immediate": True,
                                "estimatedArrivalTime": "12:30",
                                "maxWaveHeight": "50cm",
                            }
                        ],
                        "subtitle": "æµ‹è¯•åœ°ç‚¹é™„è¿‘æµ·åŸŸå‘ç”Ÿåœ°éœ‡",
                    },
                    "japan_tsunami": {  # æ—¥æœ¬æµ·å•¸é¢„è­¦æ ¼å¼ - åŸºäºP2På®é™…æ•°æ®ç»“æ„
                        "source_id": "jma_tsunami_p2p",
                        "title": "æ´¥æ³¢æ³¨æ„å ±",
                        "level": "Watch",  # P2Pä½¿ç”¨Watch/Warning/MajorWarning
                        "org_unit": "æ—¥æœ¬æ°”è±¡å…",
                        "forecasts": [
                            {
                                "name": "æµ‹è¯•åœ°ç‚¹ 1",
                                "grade": "Watch",  # P2På®é™…ä½¿ç”¨Watch/Warning/MajorWarning
                                "immediate": False,
                                "firstHeight": {
                                    "arrivalTime": "2023-12-12T13:15:00",
                                    "condition": "æ´¥æ³¢åˆ°é”ä¸­ã¨æ¨æ¸¬",
                                },
                                "maxHeight": {"description": "ï¼‘ï½", "value": 1},
                            },
                            {
                                "name": "æµ‹è¯•åœ°ç‚¹ 2",
                                "grade": "Watch",
                                "immediate": False,
                                "firstHeight": {"arrivalTime": "2023-12-12T13:25:00"},
                                "maxHeight": {"description": "ï¼ï¼ï¼•ï½", "value": 0.5},
                            },
                        ],
                        "subtitle": "ä¸‰é™¸æ²–ã‚’éœ‡æºã¨ã™ã‚‹åœ°éœ‡ã«ã‚ˆã‚Šã€æ´¥æ³¢æ³¨æ„å ±ãŒç™ºè¡¨ã•ã‚Œã¦ã„ã¾ã™ã€‚",
                        "cancelled": False,  # æ·»åŠ å–æ¶ˆçŠ¶æ€
                        "issue": {
                            "source": "æ—¥æœ¬æ°”è±¡å…",
                            "time": "2023-12-12T12:30:00",
                            "type": "Focus",
                        },
                    },
                },
                "weather": {
                    "china_weather": {  # ä¸­å›½æ°”è±¡é¢„è­¦æ ¼å¼
                        "source_id": "china_weather_fanstudio",
                        "headline": "å¤§é£é»„è‰²é¢„è­¦ä¿¡å·",
                        "title": "å¤§é£é»„è‰²é¢„è­¦ä¿¡å·",
                        "description": "æ°”è±¡å°å‘å¸ƒå¤§é£é»„è‰²é¢„è­¦ä¿¡å·ï¼šé¢„è®¡ä»Šå¤©å¤œé—´åˆ°æ˜å¤©ç™½å¤©ï¼Œæ²¿å²¸æµ·åŸŸå°†æœ‰è¥¿å—é£6ï½7çº§ï¼Œé˜µé£8ï½9çº§ã€‚",
                        "type": "wind",
                        "effective_time": datetime.now(),
                        "longitude": 116.0,
                        "latitude": 39.0,
                    }
                },
            }

            # æ ¹æ®ç¾å®³ç±»å‹å’Œæµ‹è¯•ç±»å‹é€‰æ‹©é…ç½®
            if disaster_type == "earthquake":
                if test_type == "china" or test_type is None:
                    test_config = test_configs["earthquake"]["china_eew"]
                elif test_type == "japan":
                    test_config = test_configs["earthquake"]["japan_eew"]
                elif test_type == "usgs":
                    test_config = test_configs["earthquake"]["usgs_info"]
                else:
                    test_config = test_configs["earthquake"]["china_eew"]  # é»˜è®¤

            elif disaster_type == "tsunami":
                if test_type == "japan" or test_type is None:
                    test_config = test_configs["tsunami"]["japan_tsunami"]
                elif test_type == "china":
                    test_config = test_configs["tsunami"]["china_tsunami"]
                else:
                    test_config = test_configs["tsunami"]["japan_tsunami"]  # é»˜è®¤

            elif disaster_type == "weather":
                test_config = test_configs["weather"][
                    "china_weather"
                ]  # æ°”è±¡åªæœ‰ä¸€ç§æ ¼å¼

            else:
                # é»˜è®¤ä½¿ç”¨åœ°éœ‡é…ç½®
                test_config = test_configs["earthquake"]["china_eew"]

            # åˆ›å»ºæµ‹è¯•äº‹ä»¶
            test_event = self._create_simple_test_event(disaster_type, test_config)

            logger.info(
                f"[ç¾å®³é¢„è­¦] åˆ›å»ºæµ‹è¯•äº‹ä»¶: {test_event.id} (ç±»å‹: {disaster_type}, é…ç½®: {test_config['source_id']})"
            )

            # æ³¨å…¥æœ¬åœ°é¢„ä¼°ä¿¡æ¯ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„è¾…åŠ©æ–¹æ³•ï¼‰
            if disaster_type == "earthquake" and self.message_manager.local_monitor:
                self.message_manager.local_monitor.inject_local_estimation(
                    test_event.data
                )

            # ç›´æ¥æ„å»ºæ¶ˆæ¯å¹¶æ¨é€ï¼ˆç»•è¿‡å¤æ‚çš„è¿‡æ»¤é€»è¾‘ï¼Œä»…æµ‹è¯•æ¶ˆæ¯é“¾è·¯ï¼‰
            message = self.message_manager._build_message(test_event)
            await self.message_manager._send_message(session, message)

            logger.info(f"[ç¾å®³é¢„è­¦] æµ‹è¯•æ¨é€æˆåŠŸ: {test_event.id}")

            # è¿”å›ç®€æ´çš„æˆåŠŸä¿¡æ¯
            source_name = self._get_source_display_name(test_config["source_id"])
            return f"âœ… æµ‹è¯•æ¨é€æˆåŠŸ\nğŸ“¡ æ•°æ®æº: {source_name}\nğŸ¯ æ¶ˆæ¯é“¾è·¯ç•…é€š"

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] æµ‹è¯•æ¨é€å¤±è´¥: {e}")
            return f"âŒ æµ‹è¯•æ¨é€å¤±è´¥: {str(e)}"

    def _create_simple_test_event(
        self, disaster_type: str, test_config: dict
    ) -> "DisasterEvent":
        """åˆ›å»ºç®€åŒ–çš„æµ‹è¯•äº‹ä»¶"""
        # ä½¿ç”¨é¡¶éƒ¨å¯¼å…¥çš„ç±»ï¼Œæ— éœ€åœ¨æ­¤å¤„é‡æ–°å¯¼å…¥

        source_id = test_config["source_id"]

        # è·å–æ•°æ®æºæšä¸¾å€¼
        source_enum_mapping = {
            "cea_fanstudio": DataSource.FAN_STUDIO_CEA,
            "jma_wolfx": DataSource.WOLFX_JMA_EEW,
            "usgs_fanstudio": DataSource.FAN_STUDIO_USGS,
            "china_tsunami_fanstudio": DataSource.FAN_STUDIO_TSUNAMI,
            "jma_tsunami_p2p": DataSource.P2P_TSUNAMI,
            "china_weather_fanstudio": DataSource.FAN_STUDIO_WEATHER,
        }
        source_enum = source_enum_mapping.get(source_id, DataSource.FAN_STUDIO_CEA)

        if disaster_type == "earthquake":
            # åˆ›å»ºåœ°éœ‡æµ‹è¯•æ•°æ®
            test_data = EarthquakeData(
                id=f"test_{source_id}_{int(datetime.now().timestamp())}",
                event_id=f"test_event_{source_id}",
                source=source_enum,
                disaster_type=DisasterType.EARTHQUAKE,
                shock_time=datetime.now(),
                latitude=test_config.get("latitude", 35.0),
                longitude=test_config.get("longitude", 105.0),
                magnitude=test_config.get("magnitude", 5.5),
                depth=test_config.get("depth", 10.0),
                intensity=test_config.get("intensity"),
                scale=test_config.get("scale"),
                place_name=test_config.get("place_name", "æµ‹è¯•åœ°éœ‡åœ°ç‚¹"),
                raw_data={
                    **{"test": True, "source_id": source_id},
                    **test_config.get("raw_data", {}),
                },
                info_type=test_config.get("info_type"),
                updates=test_config.get("updates", 1),
                is_final=test_config.get("is_final", False),
            )
            disaster_type_enum = DisasterType.EARTHQUAKE

        elif disaster_type == "tsunami":
            # åˆ›å»ºæµ·å•¸æµ‹è¯•æ•°æ®
            test_data = TsunamiData(
                id=f"test_{source_id}_{int(datetime.now().timestamp())}",
                code=f"test_tsunami_{source_id}",
                source=source_enum,
                title=test_config.get("title", "æµ·å•¸è­¦æŠ¥æµ‹è¯•"),
                level=test_config.get("level", "Warning"),
                org_unit=test_config.get("org_unit", "æµ‹è¯•æµ·å•¸é¢„è­¦ä¸­å¿ƒ"),
                forecasts=test_config.get("forecasts", []),
                raw_data={
                    **{"test": True, "source_id": source_id},
                    **test_config.get("raw_data", {}),
                },
                issue_time=datetime.now(),
                subtitle=test_config.get("subtitle", "æµ‹è¯•éœ‡æºä¿¡æ¯"),
            )
            disaster_type_enum = DisasterType.TSUNAMI

        elif disaster_type == "weather":
            # åˆ›å»ºæ°”è±¡é¢„è­¦æµ‹è¯•æ•°æ®
            test_data = WeatherAlarmData(
                id=f"test_{source_id}_{int(datetime.now().timestamp())}",
                source=source_enum,
                headline=test_config.get("headline", "æ°”è±¡é¢„è­¦æµ‹è¯•"),
                title=test_config.get("title", "æµ‹è¯•é¢„è­¦"),
                description=test_config.get("description", "æµ‹è¯•æè¿°"),
                type=test_config.get("type", "unknown"),
                effective_time=test_config.get("effective_time", datetime.now()),
                longitude=test_config.get("longitude", 116.0),
                latitude=test_config.get("latitude", 39.0),
                raw_data={
                    **{"test": True, "source_id": source_id},
                    **test_config.get("raw_data", {}),
                },
                issue_time=datetime.now(),
            )
            disaster_type_enum = DisasterType.WEATHER_ALARM

        else:
            # é»˜è®¤åˆ›å»ºåœ°éœ‡æ•°æ®
            return self._create_simple_test_event("earthquake", test_config)

        return DisasterEvent(
            id=test_data.id,
            data=test_data,
            source=test_data.source,
            disaster_type=disaster_type_enum,
        )

    def _get_source_display_name(self, source_id: str) -> str:
        """è·å–æ•°æ®æºæ˜¾ç¤ºåç§°"""
        from ..models.data_source_config import get_data_source_config

        config = get_data_source_config(source_id)
        if config:
            return config.display_name
        return source_id


# æœåŠ¡å®ä¾‹
_disaster_service: DisasterWarningService | None = None


async def get_disaster_service(
    config: dict[str, Any], context
) -> DisasterWarningService:
    """è·å–ç¾å®³é¢„è­¦æœåŠ¡å®ä¾‹"""
    global _disaster_service

    if _disaster_service is None:
        _disaster_service = DisasterWarningService(config, context)
        await _disaster_service.initialize()

    return _disaster_service


async def stop_disaster_service():
    """åœæ­¢ç¾å®³é¢„è­¦æœåŠ¡"""
    global _disaster_service

    if _disaster_service:
        await _disaster_service.stop()
        _disaster_service = None
