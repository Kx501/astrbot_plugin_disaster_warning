"""
æ¶ˆæ¯æ¨é€ç®¡ç†å™¨
å®ç°ä¼˜åŒ–çš„æŠ¥æ•°æ§åˆ¶ã€æ‹†åˆ†è¿‡æ»¤å™¨å’Œæ”¹è¿›çš„å»é‡é€»è¾‘
"""

import urllib.parse
from collections import defaultdict
from datetime import datetime, timedelta
from typing import Any

import astrbot.api.message_components as Comp
from astrbot.api import logger
from astrbot.api.event import MessageChain

from .data_source_config import (
    get_intensity_based_sources,
    get_scale_based_sources,
    get_sources_needing_report_control,
)
from .message_formatters import (
    BaseMessageFormatter,
    format_earthquake_message,
    format_tsunami_message,
    format_weather_message,
)
from .models import (
    DataSource,
    DisasterEvent,
    EarthquakeData,
    TsunamiData,
    WeatherAlarmData,
)


class IntensityFilter:
    """çƒˆåº¦è¿‡æ»¤å™¨ - ä¸“é—¨å¤„ç†ä½¿ç”¨çƒˆåº¦çš„æ•°æ®æº"""

    def __init__(self, min_magnitude: float = 0, min_intensity: float = 0):
        self.min_magnitude = min_magnitude
        self.min_intensity = min_intensity

    def should_filter(self, earthquake: EarthquakeData) -> bool:
        """åˆ¤æ–­æ˜¯å¦è¿‡æ»¤è¯¥åœ°éœ‡äº‹ä»¶"""
        # æ£€æŸ¥éœ‡çº§
        if (
            earthquake.magnitude is not None
            and earthquake.magnitude < self.min_magnitude
        ):
            logger.debug(
                f"[ç¾å®³é¢„è­¦] éœ‡çº§ {earthquake.magnitude} < æœ€å°éœ‡çº§ {self.min_magnitude}"
            )
            return True

        # æ£€æŸ¥çƒˆåº¦
        if (
            earthquake.intensity is not None
            and earthquake.intensity < self.min_intensity
        ):
            logger.debug(
                f"[ç¾å®³é¢„è­¦] çƒˆåº¦ {earthquake.intensity} < æœ€å°çƒˆåº¦ {self.min_intensity}"
            )
            return True

        return False


class ScaleFilter:
    """éœ‡åº¦è¿‡æ»¤å™¨ - ä¸“é—¨å¤„ç†ä½¿ç”¨éœ‡åº¦çš„æ•°æ®æº"""

    def __init__(self, min_magnitude: float = 0, min_scale: float = 0):
        self.min_magnitude = min_magnitude
        self.min_scale = min_scale

    def should_filter(self, earthquake: EarthquakeData) -> bool:
        """åˆ¤æ–­æ˜¯å¦è¿‡æ»¤è¯¥åœ°éœ‡äº‹ä»¶"""
        # æ£€æŸ¥éœ‡çº§
        if (
            earthquake.magnitude is not None
            and earthquake.magnitude < self.min_magnitude
        ):
            logger.debug(
                f"[ç¾å®³é¢„è­¦] éœ‡çº§ {earthquake.magnitude} < æœ€å°éœ‡çº§ {self.min_magnitude}"
            )
            return True

        # æ£€æŸ¥éœ‡åº¦
        if earthquake.scale is not None and earthquake.scale < self.min_scale:
            logger.debug(
                f"[ç¾å®³é¢„è­¦] éœ‡åº¦ {earthquake.scale} < æœ€å°éœ‡åº¦ {self.min_scale}"
            )
            return True

        return False


class USGSFilter:
    """USGSä¸“ç”¨è¿‡æ»¤å™¨ - åªæ£€æŸ¥éœ‡çº§"""

    def __init__(self, min_magnitude: float = 0):
        self.min_magnitude = min_magnitude

    def should_filter(self, earthquake: EarthquakeData) -> bool:
        """åˆ¤æ–­æ˜¯å¦è¿‡æ»¤è¯¥åœ°éœ‡äº‹ä»¶"""
        # USGSåªæ£€æŸ¥éœ‡çº§
        if (
            earthquake.magnitude is not None
            and earthquake.magnitude < self.min_magnitude
        ):
            logger.debug(
                f"[ç¾å®³é¢„è­¦] éœ‡çº§ {earthquake.magnitude} < æœ€å°éœ‡çº§ {self.min_magnitude}"
            )
            return True

        return False


class ReportCountController:
    """æŠ¥æ•°æ§åˆ¶å™¨ - ä»…å¯¹EEWæ•°æ®æºç”Ÿæ•ˆ"""

    def __init__(
        self,
        push_every_n_reports: int = 3,
        first_report_always_push: bool = True,
        final_report_always_push: bool = True,
    ):
        self.push_every_n_reports = push_every_n_reports
        self.first_report_always_push = first_report_always_push
        self.final_report_always_push = final_report_always_push
        # è®°å½•æ¯ä¸ªäº‹ä»¶çš„æŠ¥æ•°æ¨é€æƒ…å†µ
        self.event_report_counts: dict[str, int] = defaultdict(int)

    def should_push_report(self, event: DisasterEvent) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ¨é€è¯¥æŠ¥æ•°"""
        if not isinstance(event.data, EarthquakeData):
            return True  # éåœ°éœ‡äº‹ä»¶ç›´æ¥æ¨é€

        earthquake = event.data
        source_id = self._get_source_id(event)

        # åªå¯¹éœ€è¦æŠ¥æ•°æ§åˆ¶çš„æ•°æ®æºç”Ÿæ•ˆ
        if source_id not in get_sources_needing_report_control():
            return True

        event_id = earthquake.event_id or earthquake.id
        current_report = getattr(earthquake, "updates", 1)
        is_final = getattr(earthquake, "is_final", False)

        # æœ€ç»ˆæŠ¥æ€»æ˜¯æ¨é€
        if is_final and self.final_report_always_push:
            logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} æ˜¯æœ€ç»ˆæŠ¥ï¼Œå…è®¸æ¨é€")
            return True

        # ç¬¬1æŠ¥æ€»æ˜¯æ¨é€
        if current_report == 1 and self.first_report_always_push:
            logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} æ˜¯ç¬¬1æŠ¥ï¼Œå…è®¸æ¨é€")
            return True

        # æ£€æŸ¥æŠ¥æ•°æ§åˆ¶
        if current_report % self.push_every_n_reports == 0:
            logger.debug(
                f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} ç¬¬ {current_report} æŠ¥ï¼Œç¬¦åˆæŠ¥æ•°æ§åˆ¶è§„åˆ™"
            )
            return True

        logger.debug(
            f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} ç¬¬ {current_report} æŠ¥ï¼Œè¢«æŠ¥æ•°æ§åˆ¶è¿‡æ»¤"
        )
        return False

    def _get_source_id(self, event: DisasterEvent) -> str:
        """è·å–äº‹ä»¶çš„æ•°æ®æºID"""
        # å°†DataSourceæ˜ å°„åˆ°æˆ‘ä»¬çš„source_id
        source_mapping = {
            DataSource.FAN_STUDIO_CEA.value: "cea_fanstudio",
            DataSource.WOLFX_CENC_EEW.value: "cea_wolfx",
            DataSource.FAN_STUDIO_CWA.value: "cwa_fanstudio",
            DataSource.WOLFX_CWA_EEW.value: "cwa_wolfx",
            DataSource.P2P_EEW.value: "jma_p2p",
            DataSource.WOLFX_JMA_EEW.value: "jma_wolfx",
            DataSource.GLOBAL_QUAKE.value: "global_quake",
        }

        return source_mapping.get(event.source.value, "")


class EventDeduplicator:
    """äº‹ä»¶å»é‡å™¨ - å…è®¸å¤šæ•°æ®æºæ¨é€åŒä¸€äº‹ä»¶"""

    def __init__(
        self,
        time_window_minutes: int = 1,
        location_tolerance_km: float = 20.0,
        magnitude_tolerance: float = 0.5,
    ):
        self.time_window = timedelta(minutes=time_window_minutes)
        self.location_tolerance = location_tolerance_km
        self.magnitude_tolerance = magnitude_tolerance

        # è®°å½•æ¯ä¸ªæ•°æ®æºçš„äº‹ä»¶ï¼šäº‹ä»¶æŒ‡çº¹ -> {æ•°æ®æº: äº‹ä»¶ä¿¡æ¯}
        self.recent_events: dict[str, dict[str, dict]] = {}

    def should_push_event(self, event: DisasterEvent) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ¨é€äº‹ä»¶ - å…è®¸å¤šæ•°æ®æºæ¨é€åŒä¸€äº‹ä»¶"""
        if not isinstance(event.data, EarthquakeData):
            return True  # éåœ°éœ‡äº‹ä»¶ç›´æ¥æ¨é€

        earthquake = event.data
        source_id = self._get_source_id(event)

        # ç”Ÿæˆäº‹ä»¶æŒ‡çº¹
        event_fingerprint = self._generate_event_fingerprint(earthquake)

        # å…³é”®ä¿®å¤ï¼šå¦‚æœåœ°éœ‡æ—¶é—´è§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºåå¤‡
        current_time = (
            earthquake.shock_time
            if earthquake.shock_time is not None
            else datetime.now()
        )

        logger.debug(
            f"[ç¾å®³é¢„è­¦] æ£€æŸ¥äº‹ä»¶: {event.source.value}, æŒ‡çº¹: {event_fingerprint}"
        )

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸ä¼¼äº‹ä»¶
        if event_fingerprint in self.recent_events:
            source_events = self.recent_events[event_fingerprint]

            # æ£€æŸ¥åŒä¸€æ•°æ®æºæ˜¯å¦å·²æ¨é€è¿‡
            if source_id in source_events:
                existing_event = source_events[source_id]

                # å¦‚æœåœ¨æ—¶é—´çª—å£å†…ï¼Œæ£€æŸ¥æ˜¯å¦å…è®¸æ›´æ–°
                time_diff = abs(
                    (current_time - existing_event["timestamp"]).total_seconds() / 60
                )

                if time_diff <= self.time_window.total_seconds() / 60:
                    if self._should_allow_update(earthquake, existing_event):
                        logger.info(
                            f"[ç¾å®³é¢„è­¦] å…è®¸åŒä¸€æ•°æ®æºæ›´æ–°: {event.source.value}"
                        )
                        # æ›´æ–°è®°å½•
                        source_events[source_id] = {
                            "timestamp": current_time,
                            "source": event.source.value,
                            "latitude": earthquake.latitude or 0,
                            "longitude": earthquake.longitude or 0,
                            "magnitude": earthquake.magnitude or 0,
                            "info_type": earthquake.info_type or "",
                            "updates": getattr(earthquake, "updates", 1),
                            "is_final": getattr(earthquake, "is_final", False),
                        }
                        return True
                    else:
                        logger.info(
                            f"[ç¾å®³é¢„è­¦] åŒä¸€æ•°æ®æºé‡å¤äº‹ä»¶ï¼Œè¿‡æ»¤: {event.source.value}"
                        )
                        return False
                else:
                    logger.debug("[ç¾å®³é¢„è­¦] åŒä¸€æ•°æ®æºäº‹ä»¶å·²è¿‡æœŸï¼Œå…è®¸æ¨é€")

            # ä¸åŒæ•°æ®æºï¼Œå…è®¸æ¨é€ï¼ˆå…è®¸å¤šæ•°æ®æºæ¨é€åŒä¸€äº‹ä»¶ï¼‰
            logger.info(f"[ç¾å®³é¢„è­¦] ä¸åŒæ•°æ®æºï¼Œå…è®¸æ¨é€: {event.source.value}")
            self.recent_events[event_fingerprint][source_id] = {
                "timestamp": current_time,
                "source": event.source.value,
                "latitude": earthquake.latitude or 0,
                "longitude": earthquake.longitude or 0,
                "magnitude": earthquake.magnitude or 0,
                "info_type": earthquake.info_type or "",
                "updates": getattr(earthquake, "updates", 1),
                "is_final": getattr(earthquake, "is_final", False),
            }
            return True

        # æ–°äº‹ä»¶ï¼Œè®°å½•å¹¶å…è®¸æ¨é€
        self.recent_events[event_fingerprint] = {
            source_id: {
                "timestamp": current_time,
                "source": event.source.value,
                "latitude": earthquake.latitude or 0,
                "longitude": earthquake.longitude or 0,
                "magnitude": earthquake.magnitude or 0,
                "info_type": earthquake.info_type or "",
                "updates": getattr(earthquake, "updates", 1),
                "is_final": getattr(earthquake, "is_final", False),
            }
        }

        logger.info(f"[ç¾å®³é¢„è­¦] å…è®¸æ¨é€æ–°äº‹ä»¶: {event.source.value}")
        return True

    def _generate_event_fingerprint(self, earthquake: EarthquakeData) -> str:
        """ç”Ÿæˆäº‹ä»¶æŒ‡çº¹ - åŸºäºåœ°ç†ä½ç½®å’Œéœ‡çº§çš„ç®€åŒ–æŒ‡çº¹"""
        if not earthquake.latitude or not earthquake.longitude:
            return "unknown_location"

        # å°†åæ ‡é‡åŒ–åˆ°æŒ‡å®šç²¾åº¦ï¼ˆ20kmç½‘æ ¼ï¼‰
        lat_grid = round(earthquake.latitude * (111.0 / self.location_tolerance)) / (
            111.0 / self.location_tolerance
        )
        lon_grid = round(earthquake.longitude * (111.0 / self.location_tolerance)) / (
            111.0 / self.location_tolerance
        )

        # éœ‡çº§é‡åŒ–åˆ°å®¹å·®çº§åˆ«
        mag_grid = (
            round((earthquake.magnitude or 0) / self.magnitude_tolerance)
            * self.magnitude_tolerance
        )

        # å…³é”®ä¿®å¤ï¼šå¤„ç†æ—¶é—´å¯èƒ½ä¸ºNoneçš„æƒ…å†µ
        if earthquake.shock_time is not None:
            time_minute = earthquake.shock_time.replace(second=0, microsecond=0)
        else:
            # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´ä½†æ ‡è®°ä¸ºç‰¹æ®Šå€¼
            time_minute = datetime.now().replace(second=0, microsecond=0)

        return f"{lat_grid:.3f},{lon_grid:.3f},{mag_grid:.1f},{time_minute.strftime('%Y%m%d%H%M')}"

    def _should_allow_update(
        self, current_earthquake: EarthquakeData, existing_event: dict
    ) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å…è®¸äº‹ä»¶æ›´æ–°"""
        # æŠ¥æ•°æ›´æ–°æ£€æŸ¥
        current_updates = getattr(current_earthquake, "updates", 1)
        existing_updates = existing_event.get("updates", 1)

        if current_updates > existing_updates:
            logger.info(
                f"[ç¾å®³é¢„è­¦] æŠ¥æ•°æ›´æ–°: ç¬¬{existing_updates}æŠ¥ -> ç¬¬{current_updates}æŠ¥"
            )
            return True

        # æœ€ç»ˆæŠ¥æ£€æŸ¥
        if getattr(current_earthquake, "is_final", False) and not existing_event.get(
            "is_final", False
        ):
            logger.info("[ç¾å®³é¢„è­¦] æœ€ç»ˆæŠ¥æ›´æ–°: éæœ€ç»ˆæŠ¥ -> æœ€ç»ˆæŠ¥")
            return True

        # USGSçŠ¶æ€å‡çº§
        if current_earthquake.source == DataSource.FAN_STUDIO_USGS:
            current_info_type = (current_earthquake.info_type or "").lower()
            existing_info_type = (existing_event.get("info_type", "") or "").lower()

            if existing_info_type == "automatic" and current_info_type == "reviewed":
                logger.debug("[ç¾å®³é¢„è­¦] å…è®¸USGSçŠ¶æ€å‡çº§: automatic -> reviewed")
                return True

        # é€šç”¨çŠ¶æ€å‡çº§ï¼ˆé’ˆå¯¹CENCç­‰ï¼‰
        current_info_type = (current_earthquake.info_type or "").lower()
        existing_info_type = (existing_event.get("info_type", "") or "").lower()

        # è‡ªåŠ¨æµ‹å®š -> æ­£å¼æµ‹å®š
        if "è‡ªåŠ¨" in existing_info_type and "æ­£å¼" in current_info_type:
            logger.info(
                f"[ç¾å®³é¢„è­¦] å…è®¸çŠ¶æ€å‡çº§: {existing_info_type} -> {current_info_type}"
            )
            return True

        return False

    def _get_source_id(self, event: DisasterEvent) -> str:
        """è·å–äº‹ä»¶çš„æ•°æ®æºID"""
        source_mapping = {
            DataSource.FAN_STUDIO_CEA.value: "cea_fanstudio",
            DataSource.WOLFX_CENC_EEW.value: "cea_wolfx",
            DataSource.FAN_STUDIO_CWA.value: "cwa_fanstudio",
            DataSource.WOLFX_CWA_EEW.value: "cwa_wolfx",
            DataSource.P2P_EEW.value: "jma_p2p",
            DataSource.P2P_EARTHQUAKE.value: "jma_p2p_info",
            DataSource.WOLFX_JMA_EEW.value: "jma_wolfx",
            DataSource.FAN_STUDIO_CENC.value: "cenc_fanstudio",
            DataSource.WOLFX_CENC_EEW.value: "cenc_wolfx",
            DataSource.FAN_STUDIO_USGS.value: "usgs_fanstudio",
            DataSource.GLOBAL_QUAKE.value: "global_quake",
        }

        return source_mapping.get(event.source.value, event.source.value)

    def cleanup_old_events(self):
        """æ¸…ç†è¿‡æœŸäº‹ä»¶"""
        cutoff_time = datetime.now() - self.time_window * 2  # ä¿ç•™2å€æ—¶é—´çª—å£

        old_fingerprints = []
        for fingerprint, source_events in self.recent_events.items():
            # æ£€æŸ¥æ‰€æœ‰æ•°æ®æºçš„äº‹ä»¶æ˜¯å¦éƒ½è¿‡æœŸ
            all_expired = True
            for event_info in source_events.values():
                if event_info["timestamp"] >= cutoff_time:
                    all_expired = False
                    break

            if all_expired:
                old_fingerprints.append(fingerprint)

        for fingerprint in old_fingerprints:
            del self.recent_events[fingerprint]


class MessagePushManager:
    """æ¶ˆæ¯æ¨é€ç®¡ç†å™¨"""

    def __init__(self, config: dict[str, Any], context):
        self.config = config
        self.context = context

        # åˆå§‹åŒ–è¿‡æ»¤å™¨ - ä½¿ç”¨æ–°çš„é…ç½®è·¯å¾„
        earthquake_filters = config.get("earthquake_filters", {})

        # çƒˆåº¦è¿‡æ»¤å™¨é…ç½®
        intensity_filter_config = earthquake_filters.get("intensity_filter", {})
        self.intensity_filter = IntensityFilter(
            min_magnitude=intensity_filter_config.get("min_magnitude", 2.0),
            min_intensity=intensity_filter_config.get("min_intensity", 4.0),
        )

        # éœ‡åº¦è¿‡æ»¤å™¨é…ç½®
        scale_filter_config = earthquake_filters.get("scale_filter", {})
        self.scale_filter = ScaleFilter(
            min_magnitude=scale_filter_config.get("min_magnitude", 2.0),
            min_scale=scale_filter_config.get("min_scale", 1.0),
        )

        # USGSè¿‡æ»¤å™¨é…ç½®
        magnitude_only_filter_config = earthquake_filters.get(
            "magnitude_only_filter", {}
        )
        self.usgs_filter = USGSFilter(
            min_magnitude=magnitude_only_filter_config.get("min_magnitude", 4.5)
        )

        # åˆå§‹åŒ–æŠ¥æ•°æ§åˆ¶å™¨
        self.report_controller = ReportCountController(
            push_every_n_reports=config.get("push_frequency_control", {}).get(
                "push_every_n_reports", 3
            ),
            first_report_always_push=config.get("push_frequency_control", {}).get(
                "first_report_always_push", True
            ),
            final_report_always_push=config.get("push_frequency_control", {}).get(
                "final_report_always_push", True
            ),
        )

        # åˆå§‹åŒ–å»é‡å™¨
        self.deduplicator = EventDeduplicator(
            time_window_minutes=config.get("event_deduplication", {}).get(
                "time_window_minutes", 1
            ),
            location_tolerance_km=config.get("event_deduplication", {}).get(
                "location_tolerance_km", 20.0
            ),
            magnitude_tolerance=config.get("event_deduplication", {}).get(
                "magnitude_tolerance", 0.5
            ),
        )

        # äº‹ä»¶æ¨é€è®°å½•
        self.event_push_records: dict[str, list[dict]] = defaultdict(list)

        # ç›®æ ‡ä¼šè¯
        self.target_sessions = self._parse_target_sessions()

    def _parse_target_sessions(self) -> list[str]:
        """è§£æç›®æ ‡ä¼šè¯ - ä½¿ç”¨æ­£ç¡®çš„é…ç½®é”®å"""
        target_groups = self.config.get("target_groups", [])
        sessions = []

        for group_id in target_groups:
            if group_id:
                # ä½¿ç”¨æ­£ç¡®çš„ä¼šè¯IDæ ¼å¼
                platform_name = self.config.get("platform_name", "aiocqhttp")
                session = f"{platform_name}:GroupMessage:{group_id}"
                sessions.append(session)

        return sessions

    def should_push_event(self, event: DisasterEvent) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ¨é€äº‹ä»¶"""
        # 1. æ—¶é—´æ£€æŸ¥ï¼ˆæ‰€æœ‰äº‹ä»¶ç±»å‹ï¼‰- è¿™æ˜¯æœ€é‡è¦çš„è¿‡æ»¤
        event_time = self._get_event_time(event)
        if event_time:
            time_diff = (datetime.now() - event_time).total_seconds() / 3600  # å°æ—¶
            if time_diff > 1:
                logger.info(f"[ç¾å®³é¢„è­¦] äº‹ä»¶æ—¶é—´è¿‡æ—©ï¼ˆ{time_diff:.1f}å°æ—¶å‰ï¼‰ï¼Œè¿‡æ»¤")
                return False

        # 2. éåœ°éœ‡äº‹ä»¶æ£€æŸ¥
        if not isinstance(event.data, EarthquakeData):
            # å¯¹äºæµ·å•¸å’Œæ°”è±¡äº‹ä»¶ï¼Œåªè¿›è¡Œæ—¶é—´æ£€æŸ¥ï¼Œå…¶ä»–è¿‡æ»¤é€»è¾‘ä¸é€‚ç”¨
            return True

        # 3. åœ°éœ‡äº‹ä»¶ä¸“ç”¨è¿‡æ»¤é€»è¾‘
        earthquake = event.data
        source_id = self._get_source_id(event)

        # æ•°æ®æºä¸“ç”¨è¿‡æ»¤å™¨
        if source_id in get_intensity_based_sources():
            # ä½¿ç”¨çƒˆåº¦è¿‡æ»¤å™¨
            if self.intensity_filter.should_filter(earthquake):
                logger.info(f"[ç¾å®³é¢„è­¦] äº‹ä»¶è¢«çƒˆåº¦è¿‡æ»¤å™¨è¿‡æ»¤: {source_id}")
                return False
        elif source_id in get_scale_based_sources():
            # ä½¿ç”¨éœ‡åº¦è¿‡æ»¤å™¨
            if self.scale_filter.should_filter(earthquake):
                logger.info(f"[ç¾å®³é¢„è­¦] äº‹ä»¶è¢«éœ‡åº¦è¿‡æ»¤å™¨è¿‡æ»¤: {source_id}")
                return False
        elif source_id == "usgs_fanstudio":
            # USGSä¸“ç”¨è¿‡æ»¤å™¨
            if self.usgs_filter.should_filter(earthquake):
                logger.info(f"[ç¾å®³é¢„è­¦] äº‹ä»¶è¢«USGSè¿‡æ»¤å™¨è¿‡æ»¤: {source_id}")
                return False

        # æŠ¥æ•°æ§åˆ¶ï¼ˆä»…EEWæ•°æ®æºï¼‰
        if not self.report_controller.should_push_report(event):
            logger.info(f"[ç¾å®³é¢„è­¦] äº‹ä»¶è¢«æŠ¥æ•°æ§åˆ¶å™¨è¿‡æ»¤: {source_id}")
            return False

        return True

    def _get_event_time(self, event: DisasterEvent) -> datetime | None:
        """è·å–ç¾å®³äº‹ä»¶çš„æ—¶é—´"""
        if isinstance(event.data, EarthquakeData):
            return event.data.shock_time
        elif isinstance(event.data, TsunamiData):
            return event.data.issue_time
        elif isinstance(event.data, WeatherAlarmData):
            return event.data.effective_time or event.data.issue_time
        return None

    def _get_source_id(self, event: DisasterEvent) -> str:
        """è·å–äº‹ä»¶çš„æ•°æ®æºID"""
        source_mapping = {
            # EEWé¢„è­¦æ•°æ®æº
            DataSource.FAN_STUDIO_CEA.value: "cea_fanstudio",
            DataSource.WOLFX_CENC_EEW.value: "cea_wolfx",
            DataSource.FAN_STUDIO_CWA.value: "cwa_fanstudio",
            DataSource.WOLFX_CWA_EEW.value: "cwa_wolfx",
            DataSource.P2P_EEW.value: "jma_p2p",
            DataSource.WOLFX_JMA_EEW.value: "jma_wolfx",
            # åœ°éœ‡æƒ…æŠ¥æ•°æ®æº
            DataSource.FAN_STUDIO_CENC.value: "cenc_fanstudio",
            DataSource.WOLFX_CENC_EQ.value: "cenc_wolfx",
            DataSource.P2P_EARTHQUAKE.value: "jma_p2p_info",
            DataSource.WOLFX_JMA_EQ.value: "jma_wolfx_info",
            DataSource.FAN_STUDIO_USGS.value: "usgs_fanstudio",
            DataSource.GLOBAL_QUAKE.value: "global_quake",
            # æ°”è±¡å’Œæµ·å•¸é¢„è­¦æ•°æ®æº
            DataSource.FAN_STUDIO_WEATHER.value: "china_weather_fanstudio",
            DataSource.FAN_STUDIO_TSUNAMI.value: "china_tsunami_fanstudio",
            DataSource.P2P_TSUNAMI.value: "jma_tsunami_p2p",
        }

        return source_mapping.get(event.source.value, event.source.value)

    async def push_event(self, event: DisasterEvent) -> bool:
        """æ¨é€äº‹ä»¶"""
        logger.debug(f"[ç¾å®³é¢„è­¦] å¤„ç†äº‹ä»¶æ¨é€: {event.id}")

        # 1. å…ˆå»é‡æ£€æŸ¥ - å…è®¸å¤šæ•°æ®æºæ¨é€åŒä¸€äº‹ä»¶
        if not self.deduplicator.should_push_event(event):
            logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event.id} è¢«å»é‡å™¨è¿‡æ»¤")
            return False

        # 2. æ¨é€æ¡ä»¶æ£€æŸ¥
        if not self.should_push_event(event):
            logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event.id} æœªé€šè¿‡æ¨é€æ¡ä»¶æ£€æŸ¥")
            return False

        try:
            # 3. æ„å»ºæ¶ˆæ¯
            message = self._build_message(event)
            logger.debug("[ç¾å®³é¢„è­¦] æ¶ˆæ¯æ„å»ºå®Œæˆ")

            # 4. è·å–ç›®æ ‡ä¼šè¯
            target_sessions = self.target_sessions
            if not target_sessions:
                logger.warning("[ç¾å®³é¢„è­¦] æ²¡æœ‰é…ç½®ç›®æ ‡ä¼šè¯ï¼Œæ— æ³•æ¨é€æ¶ˆæ¯")
                return False

            # 5. æ¨é€æ¶ˆæ¯
            push_success_count = 0
            for session in target_sessions:
                try:
                    await self._send_message(session, message)
                    logger.info(f"[ç¾å®³é¢„è­¦] æ¶ˆæ¯å·²æ¨é€åˆ° {session}")
                    push_success_count += 1
                except Exception as e:
                    logger.error(f"[ç¾å®³é¢„è­¦] æ¨é€åˆ° {session} å¤±è´¥: {e}")

            # 6. è®°å½•æ¨é€
            self._record_push(event)
            logger.info(
                f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event.id} æ¨é€å®Œæˆï¼ŒæˆåŠŸæ¨é€åˆ° {push_success_count} ä¸ªä¼šè¯"
            )
            return push_success_count > 0

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] æ¨é€äº‹ä»¶å¤±è´¥: {e}")
            return False

    def _build_message(self, event: DisasterEvent) -> MessageChain:
        """æ„å»ºæ¶ˆæ¯ - ä½¿ç”¨æ ¼å¼åŒ–å™¨å¹¶åº”ç”¨æ¶ˆæ¯æ ¼å¼é…ç½®"""
        source_id = self._get_source_id(event)

        # è·å–æ¶ˆæ¯æ ¼å¼é…ç½®
        message_format_config = self.config.get("message_format", {})
        include_map = message_format_config.get("include_map", True)
        map_provider = message_format_config.get("map_provider", "baidu")
        map_zoom_level = message_format_config.get("map_zoom_level", 5)

        logger.debug(
            f"[ç¾å®³é¢„è­¦] åœ°å›¾é…ç½®: provider={map_provider}, zoom={map_zoom_level}"
        )

        if isinstance(event.data, WeatherAlarmData):
            message_text = format_weather_message(source_id, event.data)
        elif isinstance(event.data, TsunamiData):
            message_text = format_tsunami_message(source_id, event.data)
        elif isinstance(event.data, EarthquakeData):
            message_text = format_earthquake_message(source_id, event.data)
        else:
            # æœªçŸ¥äº‹ä»¶ç±»å‹ï¼Œä½¿ç”¨åŸºç¡€æ ¼å¼åŒ–
            logger.warning(f"[ç¾å®³é¢„è­¦] æœªçŸ¥äº‹ä»¶ç±»å‹: {type(event.data)}")
            message_text = f"ğŸš¨[æœªçŸ¥äº‹ä»¶]\nğŸ“‹äº‹ä»¶IDï¼š{event.id}\nâ°æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"

        # æ„å»ºæ¶ˆæ¯é“¾
        chain = [Comp.Plain(message_text)]

        # æ·»åŠ åœ°å›¾é“¾æ¥ï¼ˆä»…åœ°éœ‡äº‹ä»¶ä¸”åŒ…å«ç»çº¬åº¦ï¼‰
        if include_map and isinstance(event.data, EarthquakeData):
            if event.data.latitude is not None and event.data.longitude is not None:
                # ä½¿ç”¨æ¶ˆæ¯æ ¼å¼åŒ–å™¨ä¸­çš„ä¼˜åŒ–åœ°å›¾é“¾æ¥ç”Ÿæˆ
                from .message_formatters import BaseMessageFormatter

                map_url = BaseMessageFormatter.get_map_link(
                    event.data.latitude,
                    event.data.longitude,
                    map_provider,
                    map_zoom_level,
                    magnitude=event.data.magnitude,
                    place_name=event.data.place_name,
                )
                if map_url:
                    # å…³é”®ä¿®å¤ï¼šç»•è¿‡AstrBotçš„strip()é—®é¢˜
                    # ä½¿ç”¨é›¶å®½ç©ºæ ¼ä¿æŠ¤æ¢è¡Œï¼ŒURLç¼–ç ç¡®ä¿ç‰¹æ®Šå­—ç¬¦å¤„ç†
                    zero_width_space = "\u200b"

                    # æ¢è¡Œç»„ä»¶ï¼šä½¿ç”¨é›¶å®½ç©ºæ ¼ä¿æŠ¤æ¢è¡Œ
                    chain.append(
                        Comp.Plain(f"{zero_width_space}\nğŸ—ºï¸åœ°å›¾é“¾æ¥:{zero_width_space}")
                    )

                    # URLç»„ä»¶ï¼šå¯¹URLè¿›è¡ŒURLç¼–ç ï¼Œç¡®ä¿ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦æ­£ç¡®å¤„ç†
                    encoded_map_url = urllib.parse.quote(map_url, safe=":/?&=+")
                    chain.append(Comp.Plain(f" {encoded_map_url}"))

        return MessageChain(chain)

    def _generate_map_link(
        self, latitude: float, longitude: float, provider: str, zoom: int
    ) -> str:
        """æ ¹æ®é…ç½®ç”Ÿæˆåœ°å›¾é“¾æ¥ - å·²ç§»è‡³message_formattersæ¨¡å—"""
        # è¿™ä¸ªæ–¹æ³•ç°åœ¨ç”±message_formattersæ¨¡å—å¤„ç†
        return BaseMessageFormatter.get_map_link(
            latitude,
            longitude,
            provider,
            zoom,
            magnitude=None,  # è¿™ä¸ªæ–¹æ³•æ²¡æœ‰éœ‡çº§ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼
            place_name=None,  # è¿™ä¸ªæ–¹æ³•æ²¡æœ‰ä½ç½®ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼
        )

    async def _send_message(self, session: str, message: MessageChain):
        """å‘é€æ¶ˆæ¯åˆ°æŒ‡å®šä¼šè¯"""
        await self.context.send_message(session, message)

    def _record_push(self, event: DisasterEvent):
        """è®°å½•æ¨é€"""
        event_id = self._get_event_id(event)

        # è®°å½•æ¨é€ä¿¡æ¯
        push_info = {
            "timestamp": datetime.now(),
            "event_id": event_id,
            "disaster_type": event.disaster_type.value,
            "source": self._get_source_id(event),
        }

        self.event_push_records[event_id].append(push_info)

    def _get_event_id(self, event: DisasterEvent) -> str:
        """è·å–äº‹ä»¶ID"""
        if isinstance(event.data, EarthquakeData):
            return event.data.event_id or event.data.id
        elif isinstance(event.data, (TsunamiData, WeatherAlarmData)):
            return event.data.id
        return event.id

    def get_push_stats(self) -> dict[str, Any]:
        """è·å–æ¨é€ç»Ÿè®¡"""
        total_events = len(self.event_push_records)
        total_pushes = sum(len(records) for records in self.event_push_records.values())

        return {
            "total_events": total_events,
            "total_pushes": total_pushes,
            "recent_events": self._get_recent_events(),
        }

    def _get_recent_events(self, hours: int = 24) -> list[dict]:
        """è·å–æœ€è¿‘çš„äº‹ä»¶"""
        recent_time = datetime.now() - timedelta(hours=hours)
        recent_events = []

        for event_id, records in self.event_push_records.items():
            recent_records = [
                record for record in records if record["timestamp"] > recent_time
            ]

            if recent_records:
                recent_events.append(
                    {
                        "event_id": event_id,
                        "push_count": len(recent_records),
                        "last_push": max(
                            record["timestamp"] for record in recent_records
                        ),
                    }
                )

        return sorted(recent_events, key=lambda x: x["last_push"], reverse=True)

    def cleanup_old_records(self, days: int = 7):
        """æ¸…ç†æ—§è®°å½•"""
        cutoff_time = datetime.now() - timedelta(days=days)

        # æ¸…ç†äº‹ä»¶æ¨é€è®°å½•
        for event_id in list(self.event_push_records.keys()):
            records = self.event_push_records[event_id]
            recent_records = [
                record for record in records if record["timestamp"] > cutoff_time
            ]

            if recent_records:
                self.event_push_records[event_id] = recent_records
            else:
                del self.event_push_records[event_id]

        # æ¸…ç†å»é‡å™¨
        self.deduplicator.cleanup_old_events()

        logger.info(f"[ç¾å®³é¢„è­¦] å·²æ¸…ç† {days} å¤©å‰çš„æ¨é€è®°å½•")
